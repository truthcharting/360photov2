<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PhotoSphere Capture Pro</title>
    <meta name="theme-color" content="#1a1a2e">
    <link rel="manifest" href="data:application/json;base64,eyJuYW1lIjoiUGhvdG9TcGhlcmUgQ2FwdHVyZSBQcm8iLCJzaG9ydF9uYW1lIjoiUGhvdG9TcGhlcmUiLCJzdGFydF91cmwiOiIuLyIsImRpc3BsYXkiOiJmdWxsc2NyZWVuIiwidGhlbWVfY29sb3IiOiIjMWExYTJlIiwiYmFja2dyb3VuZF9jb2xvciI6IiMwZjBmMjMiLCJpY29ucyI6W3sic3JjIjoiZGF0YTppbWFnZS9zdmcreG1sO2Jhc2U2NCxQSE4yWnlCNGJXeHVjejBpYUhSMGNEb3ZMM2QzZHk1M015NXZjbWN2TWpBd01DOXpkbWNpSUhkcFpIUm9QU0kxTVRKaUlpQm9aV2xuYUhROUlqVXhNbUlpUGp4amFYSmpiR1VnWTNnOUlqSTFOaUlnWTNrOUlqSTFOaUlnY2owaU1UQXdJaUJtYVd4c1BTSWpOREEwTkRRMElpOCtQQzl6ZG1jKyIsInNpemVzIjoiNTEyeDUxMiIsInR5cGUiOiJpbWFnZS9zdmcreG1sIn1dfQ==">
    
    <!-- External Libraries -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/panolens/0.12.1/panolens.min.js"></script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 50%, #16213e 100%);
            color: white;
            overflow: hidden;
        }

        .container {
            position: relative;
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        .front-page {
            text-align: center;
            z-index: 1000;
            background: rgba(15, 15, 35, 0.9);
            padding: 40px;
            border-radius: 20px;
            border: 2px solid #444;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
        }

        .logo {
            font-size: 3rem;
            font-weight: bold;
            margin-bottom: 20px;
            background: linear-gradient(45deg, #4CAF50, #2196F3, #FF9800);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .subtitle {
            font-size: 1.2rem;
            color: #ccc;
            margin-bottom: 30px;
        }

        .version {
            position: absolute;
            bottom: 20px;
            right: 20px;
            color: #666;
            font-size: 0.9rem;
        }

        .start-btn {
            background: linear-gradient(45deg, #4CAF50, #2196F3);
            border: none;
            padding: 15px 40px;
            border-radius: 50px;
            font-size: 1.1rem;
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(76, 175, 80, 0.3);
        }

        .start-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 15px 40px rgba(76, 175, 80, 0.5);
        }

        .capture-interface {
            display: none;
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        .camera-view {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .ar-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }

        .crosshair {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 60px;
            height: 60px;
            border: 3px solid white;
            border-radius: 50%;
            box-shadow: 0 0 20px rgba(255, 255, 255, 0.5);
            opacity: 0.8;
        }

        .crosshair::before,
        .crosshair::after {
            content: '';
            position: absolute;
            background: white;
        }

        .crosshair::before {
            top: 50%;
            left: 25%;
            width: 50%;
            height: 2px;
            transform: translateY(-50%);
        }

        .crosshair::after {
            left: 50%;
            top: 25%;
            width: 2px;
            height: 50%;
            transform: translateX(-50%);
        }

        .capture-controls {
            position: absolute;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 20px;
            z-index: 1000;
        }

        .control-btn {
            background: rgba(0, 0, 0, 0.7);
            border: 2px solid #fff;
            color: white;
            padding: 12px 24px;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
        }

        .control-btn:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: scale(1.05);
        }

        .status-bar {
            position: absolute;
            top: 20px;
            left: 20px;
            right: 20px;
            background: rgba(0, 0, 0, 0.7);
            padding: 15px;
            border-radius: 10px;
            backdrop-filter: blur(10px);
            z-index: 1000;
        }

        .progress {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }

        .progress-bar {
            flex: 1;
            height: 8px;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 4px;
            margin: 0 15px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #4CAF50, #2196F3);
            width: 0%;
            transition: width 0.3s ease;
        }

        .permission-modal {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            display: none;
            justify-content: center;
            align-items: center;
            z-index: 2000;
        }

        .modal-content {
            background: #1a1a2e;
            padding: 30px;
            border-radius: 15px;
            text-align: center;
            max-width: 400px;
            border: 2px solid #444;
        }

        .modal-title {
            font-size: 1.5rem;
            margin-bottom: 15px;
            color: #4CAF50;
        }

        .modal-text {
            margin-bottom: 25px;
            line-height: 1.5;
        }

        .modal-btn {
            background: #4CAF50;
            border: none;
            padding: 12px 30px;
            border-radius: 25px;
            color: white;
            cursor: pointer;
            margin: 0 10px;
            transition: all 0.3s ease;
        }

        .modal-btn:hover {
            background: #45a049;
            transform: translateY(-2px);
        }

        .modal-btn.cancel {
            background: #f44336;
        }

        .modal-btn.cancel:hover {
            background: #da190b;
        }

        .viewer-interface {
            display: none;
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: #000;
        }

        .viewer-controls {
            position: absolute;
            top: 20px;
            left: 20px;
            right: 20px;
            z-index: 1000;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .back-btn {
            background: rgba(0, 0, 0, 0.7);
            border: 2px solid #fff;
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            cursor: pointer;
            backdrop-filter: blur(10px);
        }

        .loading-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.9);
            display: none;
            justify-content: center;
            align-items: center;
            z-index: 3000;
        }

        .loading-content {
            text-align: center;
        }

        .spinner {
            width: 50px;
            height: 50px;
            border: 3px solid #333;
            border-top: 3px solid #4CAF50;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin: 0 auto 20px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .compass-debug {
            position: absolute;
            top: 100px;
            left: 20px;
            background: rgba(0, 0, 0, 0.7);
            padding: 10px;
            border-radius: 5px;
            font-family: monospace;
            font-size: 0.8rem;
            z-index: 1000;
        }

        @media (max-width: 768px) {
            .logo {
                font-size: 2rem;
            }
            
            .front-page {
                padding: 30px 20px;
                margin: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Front Page -->
        <div class="front-page" id="frontPage">
            <div class="logo">📸 PhotoSphere Capture Pro</div>
            <div class="subtitle">Professional 360° Panoramic Photography</div>
            <button class="start-btn" onclick="requestPermissions()">Start Capture</button>
            <div class="version">v2.0.0</div>
        </div>

        <!-- Permission Modal -->
        <div class="permission-modal" id="permissionModal">
            <div class="modal-content">
                <div class="modal-title">Permissions Required</div>
                <div class="modal-text" id="modalText">
                    This app needs access to your camera and device orientation to capture 360° photospheres.
                </div>
                <button class="modal-btn" onclick="handlePermission(true)">Allow</button>
                <button class="modal-btn cancel" onclick="handlePermission(false)">Cancel</button>
            </div>
        </div>

        <!-- Loading Overlay -->
        <div class="loading-overlay" id="loadingOverlay">
            <div class="loading-content">
                <div class="spinner"></div>
                <div>Processing images...</div>
                <div id="loadingText">Analyzing image features...</div>
            </div>
        </div>

        <!-- Capture Interface -->
        <div class="capture-interface" id="captureInterface">
            <video class="camera-view" id="cameraView" autoplay playsinline></video>
            <canvas class="ar-overlay" id="arOverlay"></canvas>
            
            <!-- Status Bar -->
            <div class="status-bar">
                <div class="progress">
                    <span>Progress:</span>
                    <div class="progress-bar">
                        <div class="progress-fill" id="progressFill"></div>
                    </div>
                    <span id="progressText">0/51</span>
                </div>
                <div>Hold crosshair on blue dot for auto-capture</div>
            </div>

            <!-- Crosshair -->
            <div class="crosshair"></div>

            <!-- Capture Controls -->
            <div class="capture-controls">
                <button class="control-btn" onclick="manualCapture()">📷 Manual</button>
                <button class="control-btn" onclick="finishCapture()">✅ Finish</button>
                <button class="control-btn" onclick="cancelCapture()">❌ Cancel</button>
            </div>

            <!-- Debug Info -->
            <div class="compass-debug" id="compassDebug">
                <div>α: <span id="alpha">0</span>°</div>
                <div>β: <span id="beta">0</span>°</div>
                <div>γ: <span id="gamma">0</span>°</div>
                <div>Smooth α: <span id="smoothAlpha">0</span>°</div>
            </div>
        </div>

        <!-- Viewer Interface -->
        <div class="viewer-interface" id="viewerInterface">
            <div class="viewer-controls">
                <button class="back-btn" onclick="backToCapture()">← Back</button>
                <button class="control-btn" onclick="downloadPhotosphere()">💾 Download</button>
            </div>
            <div id="photosphereViewer"></div>
        </div>
    </div>

    <script>
        // Global variables
        let cameraStream = null;
        let threeRenderer = null;
        let threeScene = null;
        let threeCamera = null;
        let sphereGeometry = null;
        let dotMeshes = [];
        let capturedImageMeshes = [];
        let orientationData = { alpha: 0, beta: 0, gamma: 0, smoothAlpha: 0 };
        let previousAlpha = null;
        let capturedImages = [];
        let capturePoints = [];
        let isCapturing = false;
        let autoCaptureCooldown = false;
        let photosphereViewer = null;
        let arCanvas = null;
        let deviceOrientationQuaternion = new THREE.Quaternion();

        // Smooth orientation handling to prevent horizon glitches
        function smoothOrientationTransition(newAlpha, currentAlpha) {
            if (previousAlpha === null) {
                previousAlpha = newAlpha;
                return newAlpha;
            }

            let diff = newAlpha - previousAlpha;
            
            // Handle 360° to 0° transition (crossing north)
            if (diff > 180) {
                diff -= 360;
            } else if (diff < -180) {
                diff += 360;
            }
            
            // Apply exponential smoothing
            const smoothingFactor = 0.15; // Lower = smoother, higher = more responsive
            const smoothedDiff = diff * smoothingFactor;
            let result = previousAlpha + smoothedDiff;
            
            // Normalize to 0-360 range
            if (result < 0) result += 360;
            if (result >= 360) result -= 360;
            
            previousAlpha = result;
            return result;
        }

        // Generate capture points using Fibonacci sphere distribution
        function generateCapturePoints() {
            const points = [];
            const numPoints = 51;
            const goldenRatio = (1 + Math.sqrt(5)) / 2;
            
            for (let i = 0; i < numPoints; i++) {
                const theta = 2 * Math.PI * i / goldenRatio;
                const phi = Math.acos(1 - 2 * (i + 0.5) / numPoints);
                
                const radius = 5;
                const x = radius * Math.sin(phi) * Math.cos(theta);
                const y = radius * Math.cos(phi);
                const z = radius * Math.sin(phi) * Math.sin(theta);
                
                points.push({
                    id: i,
                    position: new THREE.Vector3(x, y, z),
                    captured: false,
                    image: null,
                    mesh: null,
                    cameraOrientation: null
                });
            }
            
            return points;
        }

        function initializeCapturePoints() {
            capturePoints = generateCapturePoints();
            console.log(`Generated ${capturePoints.length} capture points`);
        }

        function initializeThreeScene() {
            threeRenderer = new THREE.WebGLRenderer({ 
                canvas: arCanvas,
                antialias: true,
                alpha: true 
            });
            threeRenderer.setSize(window.innerWidth, window.innerHeight);
            threeRenderer.setPixelRatio(window.devicePixelRatio);
            
            threeScene = new THREE.Scene();
            threeCamera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 100);
            threeCamera.position.set(0, 0, 0);
            
            sphereGeometry = new THREE.SphereGeometry(0.1, 16, 16);
            createCapturePointMeshes();
            threeRenderer.setAnimationLoop(renderThreeScene);
        }

        function createCapturePointMeshes() {
            dotMeshes = [];
            
            capturePoints.forEach((point, index) => {
                const material = new THREE.MeshBasicMaterial({ 
                    color: 0x2196F3,
                    transparent: true,
                    opacity: 0.8
                });
                
                const mesh = new THREE.Mesh(sphereGeometry, material);
                mesh.position.copy(point.position);
                mesh.userData = { pointIndex: index, captured: false };
                
                threeScene.add(mesh);
                dotMeshes.push(mesh);
                point.mesh = mesh;
            });
        }

        function updateDeviceOrientation() {
            if (!threeCamera) return;

            // Use smoothed alpha to prevent horizon glitches
            const alphaRad = THREE.MathUtils.degToRad(orientationData.smoothAlpha);
            const betaRad = THREE.MathUtils.degToRad(orientationData.beta || 0);
            const gammaRad = THREE.MathUtils.degToRad(orientationData.gamma || 0);

            const euler = new THREE.Euler(betaRad, gammaRad, alphaRad, 'ZXY');
            deviceOrientationQuaternion.setFromEuler(euler);
            threeCamera.quaternion.copy(deviceOrientationQuaternion);
        }

        function renderThreeScene() {
            if (!threeRenderer || !threeScene || !threeCamera) return;
            
            updateDeviceOrientation();
            updateDotStates();
            checkForAutoCapture();
            threeRenderer.render(threeScene, threeCamera);
        }

        function updateDotStates() {
            dotMeshes.forEach((mesh, index) => {
                const point = capturePoints[index];
                
                if (point.captured) {
                    mesh.material.color.setHex(0x4CAF50);
                    mesh.material.opacity = 0.6;
                } else {
                    mesh.material.color.setHex(0x2196F3);
                    mesh.material.opacity = 0.8;
                    
                    if (isDotInCrosshair(mesh)) {
                        mesh.material.color.setHex(0xFF9800);
                        const pulse = 1 + 0.3 * Math.sin(Date.now() / 200);
                        mesh.scale.setScalar(pulse);
                    } else {
                        mesh.scale.setScalar(1);
                    }
                }
            });
        }

        function isDotInCrosshair(mesh) {
            const vector = mesh.position.clone();
            vector.project(threeCamera);
            
            const screenX = (vector.x * 0.5 + 0.5) * window.innerWidth;
            const screenY = (-vector.y * 0.5 + 0.5) * window.innerHeight;
            
            if (vector.z > 1) return false;
            
            const centerX = window.innerWidth / 2;
            const centerY = window.innerHeight / 2;
            const distance = Math.sqrt(
                Math.pow(screenX - centerX, 2) + 
                Math.pow(screenY - centerY, 2)
            );
            
            return distance < 40;
        }

        function checkForAutoCapture() {
            if (autoCaptureCooldown) return;
            
            for (let i = 0; i < dotMeshes.length; i++) {
                const mesh = dotMeshes[i];
                const point = capturePoints[i];
                
                if (!point.captured && isDotInCrosshair(mesh)) {
                    autoCaptureCooldown = true;
                    setTimeout(() => {
                        if (!point.captured && isDotInCrosshair(mesh)) {
                            captureImageAtPoint(i);
                        }
                        autoCaptureCooldown = false;
                    }, 1000);
                    break;
                }
            }
        }

        // Enhanced image capture with proper orientation and sizing
        function captureImageAtPoint(pointIndex) {
            const point = capturePoints[pointIndex];
            if (point.captured) return;
            
            const video = document.getElementById('cameraView');
            const canvas = document.createElement('canvas');
            const context = canvas.getContext('2d');
            
            // Capture at native resolution
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            
            // Store current device orientation for proper image placement
            const currentOrientation = {
                alpha: orientationData.smoothAlpha,
                beta: orientationData.beta,
                gamma: orientationData.gamma,
                quaternion: deviceOrientationQuaternion.clone()
            };
            
            // Apply proper rotation based on device orientation
            context.save();
            context.translate(canvas.width / 2, canvas.height / 2);
            
            // Correct for device rotation
            const deviceRotation = screen.orientation ? screen.orientation.angle : 0;
            context.rotate(THREE.MathUtils.degToRad(-deviceRotation));
            
            context.translate(-canvas.width / 2, -canvas.height / 2);
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            context.restore();
            
            const imageData = canvas.toDataURL('image/jpeg', 0.95);
            
            point.captured = true;
            point.image = imageData;
            point.cameraOrientation = currentOrientation;
            
            capturedImages.push({
                data: imageData,
                position: point.position.clone(),
                orientation: currentOrientation,
                pointIndex: pointIndex,
                timestamp: Date.now()
            });
            
            createEnhancedImageMeshAtPoint(point, imageData, currentOrientation);
            updateProgress();
            showCaptureFlash();
        }

        // Enhanced 3D image placement with correct orientation and size
        function createEnhancedImageMeshAtPoint(point, imageData, orientation) {
            const img = new Image();
            img.onload = () => {
                const texture = new THREE.Texture(img);
                texture.needsUpdate = true;
                
                // Calculate proper aspect ratio and size
                const aspectRatio = img.width / img.height;
                const baseSize = 1.2; // Larger base size for life-size appearance
                
                let width, height;
                if (aspectRatio > 1) {
                    width = baseSize * aspectRatio;
                    height = baseSize;
                } else {
                    width = baseSize;
                    height = baseSize / aspectRatio;
                }
                
                const planeGeometry = new THREE.PlaneGeometry(width, height);
                const planeMaterial = new THREE.MeshBasicMaterial({ 
                    map: texture,
                    transparent: true,
                    opacity: 0.9,
                    side: THREE.DoubleSide
                });
                
                const imageMesh = new THREE.Mesh(planeGeometry, planeMaterial);
                
                // Position image closer to the capture point for life-size appearance
                const direction = point.position.clone().normalize();
                imageMesh.position.copy(direction.multiplyScalar(4.2));
                
                // Apply proper orientation based on capture orientation
                imageMesh.quaternion.copy(orientation.quaternion);
                
                // Additional rotation to ensure image faces correctly
                const lookAtQuaternion = new THREE.Quaternion();
                const lookAtMatrix = new THREE.Matrix4();
                lookAtMatrix.lookAt(imageMesh.position, new THREE.Vector3(0, 0, 0), new THREE.Vector3(0, 1, 0));
                lookAtQuaternion.setFromRotationMatrix(lookAtMatrix);
                
                // Combine orientations for proper display
                imageMesh.quaternion.multiplyQuaternions(lookAtQuaternion, orientation.quaternion);
                
                threeScene.add(imageMesh);
                capturedImageMeshes.push(imageMesh);
            };
            img.src = imageData;
        }

        function updateProgress() {
            const captured = capturedImages.length;
            const total = capturePoints.length;
            const percentage = (captured / total) * 100;
            
            document.getElementById('progressFill').style.width = percentage + '%';
            document.getElementById('progressText').textContent = `${captured}/${total}`;
        }

        function showCaptureFlash() {
            const flash = document.createElement('div');
            flash.style.cssText = `
                position: fixed;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                background: white;
                opacity: 0.8;
                z-index: 10000;
                pointer-events: none;
            `;
            document.body.appendChild(flash);
            
            setTimeout(() => {
                flash.style.opacity = '0';
                setTimeout(() => document.body.removeChild(flash), 200);
            }, 100);
        }

        function manualCapture() {
            // Find the closest uncaptured dot to crosshair
            let closestDot = null;
            let closestDistance = Infinity;
            
            for (let i = 0; i < dotMeshes.length; i++) {
                const mesh = dotMeshes[i];
                const point = capturePoints[i];
                
                if (!point.captured) {
                    const vector = mesh.position.clone();
                    vector.project(threeCamera);
                    
                    if (vector.z <= 1) {
                        const screenX = (vector.x * 0.5 + 0.5) * window.innerWidth;
                        const screenY = (-vector.y * 0.5 + 0.5) * window.innerHeight;
                        
                        const centerX = window.innerWidth / 2;
                        const centerY = window.innerHeight / 2;
                        const distance = Math.sqrt(
                            Math.pow(screenX - centerX, 2) + 
                            Math.pow(screenY - centerY, 2)
                        );
                        
                        if (distance < closestDistance) {
                            closestDistance = distance;
                            closestDot = i;
                        }
                    }
                }
            }
            
            if (closestDot !== null && closestDistance < 100) {
                captureImageAtPoint(closestDot);
            } else {
                alert('Point crosshair at an uncaptured blue dot to capture.');
            }
        }

        // Enhanced orientation handling with smooth transitions
        function handleOrientation(event) {
            const rawAlpha = event.alpha || 0;
            const rawBeta = event.beta || 0;
            const rawGamma = event.gamma || 0;
            
            // Apply smoothing to alpha to prevent horizon glitches
            const smoothAlpha = smoothOrientationTransition(rawAlpha, orientationData.smoothAlpha);
            
            orientationData.alpha = rawAlpha;
            orientationData.beta = rawBeta;
            orientationData.gamma = rawGamma;
            orientationData.smoothAlpha = smoothAlpha;
            
            // Update debug display
            document.getElementById('alpha').textContent = Math.round(rawAlpha);
            document.getElementById('beta').textContent = Math.round(rawBeta);
            document.getElementById('gamma').textContent = Math.round(rawGamma);
            document.getElementById('smoothAlpha').textContent = Math.round(smoothAlpha);
        }

        async function setupCamera() {
            try {
                const constraints = {
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                };
                
                cameraStream = await navigator.mediaDevices.getUserMedia(constraints);
                const video = document.getElementById('cameraView');
                video.srcObject = cameraStream;
                
                video.addEventListener('loadedmetadata', () => {
                    setupWebXRScene();
                });
                
                return true;
            } catch (error) {
                console.error('Camera setup failed:', error);
                alert('Camera access failed. Please check permissions.');
                return false;
            }
        }

        function setupWebXRScene() {
            arCanvas = document.getElementById('arOverlay');
            arCanvas.width = window.innerWidth;
            arCanvas.height = window.innerHeight;
            initializeThreeScene();
        }

        async function requestPermissions() {
            showModal('Device Orientation Required', 'We need access to your device orientation for AR guidance.');
        }

        async function handlePermission(granted) {
            hideModal();
            
            if (!granted) {
                alert('Permissions are required for this app to function.');
                return;
            }
            
            if (typeof DeviceOrientationEvent.requestPermission === 'function') {
                try {
                    const permission = await DeviceOrientationEvent.requestPermission();
                    if (permission !== 'granted') {
                        alert('Device orientation permission denied.');
                        return;
                    }
                } catch (error) {
                    console.error('Orientation permission error:', error);
                }
            }
            
            const cameraSuccess = await setupCamera();
            if (!cameraSuccess) return;
            
            initializeCapturePoints();
            
            if (window.DeviceOrientationEvent) {
                window.addEventListener('deviceorientation', handleOrientation);
            } else {
                alert('Device orientation not supported on this device.');
                return;
            }
            
            document.getElementById('frontPage').style.display = 'none';
            document.getElementById('captureInterface').style.display = 'block';
        }

        function showModal(title, text) {
            document.getElementById('permissionModal').querySelector('.modal-title').textContent = title;
            document.getElementById('modalText').textContent = text;
            document.getElementById('permissionModal').style.display = 'flex';
        }

        function hideModal() {
            document.getElementById('permissionModal').style.display = 'none';
        }

        function showLoading(text = 'Processing...') {
            document.getElementById('loadingText').textContent = text;
            document.getElementById('loadingOverlay').style.display = 'flex';
        }

        function hideLoading() {
            document.getElementById('loadingOverlay').style.display = 'none';
        }

        // Enhanced finish capture with minimum 2 images requirement
        async function finishCapture() {
            if (capturedImages.length < 2) {
                alert('Please capture at least 2 images for panorama stitching.');
                return;
            }
            
            showLoading('Analyzing captured images...');
            
            try {
                if (cameraStream) {
                    cameraStream.getTracks().forEach(track => track.stop());
                    cameraStream = null;
                }
                
                window.removeEventListener('deviceorientation', handleOrientation);
                
                await enhancedImageStitching();
                await createPhotosphere();
                
                hideLoading();
                showViewer();
                
            } catch (error) {
                console.error('Stitching failed:', error);
                hideLoading();
                alert('Failed to create photosphere. Please try again.');
            }
        }

        // Enhanced smart image stitching algorithm
        async function enhancedImageStitching() {
            showLoading('Analyzing image features...');
            
            // Step 1: Feature detection and matching
            const imageFeatures = await extractImageFeatures();
            
            showLoading('Finding image overlaps...');
            
            // Step 2: Find overlapping images and match features
            const imagePairs = await findOverlappingImages(imageFeatures);
            
            showLoading('Calculating transformations...');
            
            // Step 3: Calculate homography matrices for each image pair
            const transformations = await calculateImageTransformations(imagePairs);
            
            showLoading('Optimizing image placement...');
            
            // Step 4: Global optimization to minimize distortion
            const optimizedPlacements = await optimizeImagePlacements(transformations);
            
            showLoading('Blending images...');
            
            // Step 5: Multi-band blending for seamless transitions
            await performMultiBandBlending(optimizedPlacements);
            
            console.log('Enhanced stitching complete');
        }

        // Feature extraction using simplified computer vision techniques
        async function extractImageFeatures() {
            const features = [];
            
            for (let i = 0; i < capturedImages.length; i++) {
                showLoading(`Analyzing image ${i + 1}/${capturedImages.length}...`);
                
                const img = capturedImages[i];
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d');
                
                // Load image
                const imageElement = new Image();
                await new Promise(resolve => {
                    imageElement.onload = resolve;
                    imageElement.src = img.data;
                });
                
                canvas.width = imageElement.width;
                canvas.height = imageElement.height;
                ctx.drawImage(imageElement, 0, 0);
                
                // Extract features (simplified Harris corner detection)
                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                const corners = detectCorners(imageData);
                const descriptors = computeDescriptors(imageData, corners);
                
                features.push({
                    imageIndex: i,
                    corners: corners,
                    descriptors: descriptors,
                    position: img.position,
                    orientation: img.orientation
                });
                
                await new Promise(resolve => setTimeout(resolve, 50)); // Allow UI updates
            }
            
            return features;
        }

        // Simplified corner detection (Harris-like algorithm)
        function detectCorners(imageData) {
            const corners = [];
            const data = imageData.data;
            const width = imageData.width;
            const height = imageData.height;
            
            // Convert to grayscale and apply Gaussian blur
            const gray = new Float32Array(width * height);
            for (let i = 0; i < data.length; i += 4) {
                const idx = i / 4;
                gray[idx] = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];
            }
            
            // Simplified corner detection
            for (let y = 3; y < height - 3; y += 4) { // Sample every 4 pixels for performance
                for (let x = 3; x < width - 3; x += 4) {
                    const idx = y * width + x;
                    
                    // Calculate gradients
                    const gx = gray[idx + 1] - gray[idx - 1];
                    const gy = gray[idx + width] - gray[idx - width];
                    
                    // Simple corner response
                    const response = Math.abs(gx * gy);
                    
                    if (response > 100) { // Threshold for corner detection
                        corners.push({ x: x, y: y, response: response });
                    }
                }
            }
            
            // Sort by response and keep top corners
            corners.sort((a, b) => b.response - a.response);
            return corners.slice(0, 100); // Keep top 100 corners
        }

        // Compute feature descriptors around corners
        function computeDescriptors(imageData, corners) {
            const descriptors = [];
            const data = imageData.data;
            const width = imageData.width;
            
            corners.forEach(corner => {
                const descriptor = [];
                const patchSize = 16;
                const halfPatch = patchSize / 2;
                
                for (let dy = -halfPatch; dy < halfPatch; dy += 2) {
                    for (let dx = -halfPatch; dx < halfPatch; dx += 2) {
                        const x = corner.x + dx;
                        const y = corner.y + dy;
                        
                        if (x >= 0 && x < width && y >= 0 && y < imageData.height) {
                            const idx = (y * width + x) * 4;
                            const intensity = 0.299 * data[idx] + 0.587 * data[idx + 1] + 0.114 * data[idx + 2];
                            descriptor.push(intensity);
                        } else {
                            descriptor.push(0);
                        }
                    }
                }
                
                descriptors.push(descriptor);
            });
            
            return descriptors;
        }

        // Find overlapping images based on 3D positions and feature matching
        async function findOverlappingImages(imageFeatures) {
            const pairs = [];
            
            for (let i = 0; i < imageFeatures.length; i++) {
                for (let j = i + 1; j < imageFeatures.length; j++) {
                    const img1 = imageFeatures[i];
                    const img2 = imageFeatures[j];
                    
                    // Check 3D distance between capture positions
                    const distance = img1.position.distanceTo(img2.position);
                    
                    if (distance < 3.0) { // Images captured close to each other likely overlap
                        // Match features between images
                        const matches = matchFeatures(img1.descriptors, img2.descriptors);
                        
                        if (matches.length > 10) { // Minimum matches for valid pair
                            pairs.push({
                                image1: i,
                                image2: j,
                                matches: matches,
                                distance: distance,
                                overlap: Math.max(0, 1 - distance / 3.0) // Estimated overlap percentage
                            });
                        }
                    }
                }
            }
            
            return pairs.sort((a, b) => b.matches.length - a.matches.length); // Sort by match quality
        }

        // Feature matching using simplified nearest neighbor
        function matchFeatures(descriptors1, descriptors2) {
            const matches = [];
            
            for (let i = 0; i < descriptors1.length; i++) {
                let bestMatch = -1;
                let bestDistance = Infinity;
                let secondBestDistance = Infinity;
                
                for (let j = 0; j < descriptors2.length; j++) {
                    const distance = computeDescriptorDistance(descriptors1[i], descriptors2[j]);
                    
                    if (distance < bestDistance) {
                        secondBestDistance = bestDistance;
                        bestDistance = distance;
                        bestMatch = j;
                    } else if (distance < secondBestDistance) {
                        secondBestDistance = distance;
                    }
                }
                
                // Lowe's ratio test for good matches
                if (bestMatch !== -1 && bestDistance / secondBestDistance < 0.8) {
                    matches.push({
                        idx1: i,
                        idx2: bestMatch,
                        distance: bestDistance
                    });
                }
            }
            
            return matches;
        }

        function computeDescriptorDistance(desc1, desc2) {
            let sum = 0;
            for (let i = 0; i < desc1.length && i < desc2.length; i++) {
                const diff = desc1[i] - desc2[i];
                sum += diff * diff;
            }
            return Math.sqrt(sum);
        }

        // Calculate transformation matrices for image pairs
        async function calculateImageTransformations(imagePairs) {
            const transformations = [];
            
            for (const pair of imagePairs) {
                // Simplified homography calculation
                // In a full implementation, this would use RANSAC for robust estimation
                const transform = {
                    image1: pair.image1,
                    image2: pair.image2,
                    matrix: calculateSimpleTransform(pair),
                    confidence: Math.min(1.0, pair.matches.length / 50)
                };
                
                transformations.push(transform);
            }
            
            return transformations;
        }

        function calculateSimpleTransform(pair) {
            // Simplified transformation based on 3D positions
            const img1 = capturedImages[pair.image1];
            const img2 = capturedImages[pair.image2];
            
            // Calculate rotation difference
            const q1 = img1.orientation.quaternion;
            const q2 = img2.orientation.quaternion;
            const relativeRotation = q1.clone().inverse().multiply(q2);
            
            // Convert to matrix (simplified 2D projection)
            const euler = new THREE.Euler().setFromQuaternion(relativeRotation);
            
            return {
                rotation: euler.y, // Yaw rotation for panorama
                translation: {
                    x: (img2.position.x - img1.position.x) * 100,
                    y: (img2.position.y - img1.position.y) * 100
                },
                scale: 1.0
            };
        }

        // Optimize image placements globally
        async function optimizeImagePlacements(transformations) {
            // Simplified global optimization
            const placements = [];
            
            // Start with first image at origin
            placements.push({
                imageIndex: 0,
                x: 0,
                y: 0,
                rotation: 0,
                scale: 1.0
            });
            
            // Place other images relative to their best matches
            for (let i = 1; i < capturedImages.length; i++) {
                let bestPlacement = null;
                let bestConfidence = 0;
                
                for (const transform of transformations) {
                    if (transform.image2 === i && placements[transform.image1]) {
                        const refPlacement = placements[transform.image1];
                        const newPlacement = {
                            imageIndex: i,
                            x: refPlacement.x + transform.matrix.translation.x,
                            y: refPlacement.y + transform.matrix.translation.y,
                            rotation: refPlacement.rotation + transform.matrix.rotation,
                            scale: refPlacement.scale * transform.matrix.scale
                        };
                        
                        if (transform.confidence > bestConfidence) {
                            bestPlacement = newPlacement;
                            bestConfidence = transform.confidence;
                        }
                    }
                }
                
                placements[i] = bestPlacement || {
                    imageIndex: i,
                    x: i * 200, // Fallback placement
                    y: 0,
                    rotation: 0,
                    scale: 1.0
                };
            }
            
            return placements;
        }

        // Multi-band blending for seamless image transitions
        async function performMultiBandBlending(placements) {
            showLoading('Performing final image blending...');
            
            // This is a simplified version - real multi-band blending is complex
            // For now, we'll create a weighted blend based on image positions
            window.optimizedPlacements = placements;
            
            await new Promise(resolve => setTimeout(resolve, 1000)); // Simulate processing
            console.log('Multi-band blending complete');
        }

        // Create enhanced photosphere with proper stitching
        async function createPhotosphere() {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            
            // Equirectangular dimensions (2:1 ratio)
            canvas.width = 4096;
            canvas.height = 2048;
            
            // Create sky gradient background
            const gradient = ctx.createLinearGradient(0, 0, canvas.width, canvas.height);
            gradient.addColorStop(0, '#87CEEB');
            gradient.addColorStop(0.7, '#98FB98');
            gradient.addColorStop(1, '#228B22');
            
            ctx.fillStyle = gradient;
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            
            // Place images using optimized placements if available
            if (window.optimizedPlacements) {
                await placeOptimizedImages(ctx, canvas, window.optimizedPlacements);
            } else {
                await placeImagesSimple(ctx, canvas);
            }
            
            window.stitchedPhotosphere = canvas.toDataURL('image/jpeg', 0.95);
        }

        async function placeOptimizedImages(ctx, canvas, placements) {
            for (const placement of placements) {
                if (placement && capturedImages[placement.imageIndex]) {
                    const img = new Image();
                    img.src = capturedImages[placement.imageIndex].data;
                    
                    await new Promise(resolve => {
                        img.onload = () => {
                            ctx.save();
                            
                            // Calculate position in equirectangular space
                            const x = (placement.x + canvas.width / 2) % canvas.width;
                            const y = placement.y + canvas.height / 2;
                            
                            // Apply transformations
                            ctx.translate(x, y);
                            ctx.rotate(placement.rotation);
                            ctx.scale(placement.scale, placement.scale);
                            
                            // Draw image with blending
                            ctx.globalAlpha = 0.8;
                            ctx.globalCompositeOperation = 'source-over';
                            
                            const drawWidth = img.width * 0.3;
                            const drawHeight = img.height * 0.3;
                            ctx.drawImage(img, -drawWidth / 2, -drawHeight / 2, drawWidth, drawHeight);
                            
                            ctx.restore();
                            resolve();
                        };
                    });
                }
            }
        }

        async function placeImagesSimple(ctx, canvas) {
            // Fallback: simple grid placement
            const cols = Math.ceil(Math.sqrt(capturedImages.length));
            const rows = Math.ceil(capturedImages.length / cols);
            
            for (let i = 0; i < capturedImages.length; i++) {
                const img = new Image();
                img.src = capturedImages[i].data;
                
                await new Promise(resolve => {
                    img.onload = () => {
                        const col = i % cols;
                        const row = Math.floor(i / cols);
                        
                        const x = (col * canvas.width / cols);
                        const y = (row * canvas.height / rows);
                        const w = canvas.width / cols;
                        const h = canvas.height / rows;
                        
                        ctx.globalAlpha = 0.8;
                        ctx.drawImage(img, x, y, w, h);
                        resolve();
                    };
                });
            }
        }

        function showViewer() {
            document.getElementById('captureInterface').style.display = 'none';
            document.getElementById('viewerInterface').style.display = 'block';
            
            if (window.stitchedPhotosphere) {
                initializePhotosphereViewer();
            }
        }

        function initializePhotosphereViewer() {
            const viewerContainer = document.getElementById('photosphereViewer');
            viewerContainer.innerHTML = '';
            
            try {
                const viewer = new PANOLENS.Viewer({
                    container: viewerContainer,
                    autoRotate: true,
                    autoRotateSpeed: 0.5,
                    controlBar: true
                });
                
                const panorama = new PANOLENS.ImagePanorama(window.stitchedPhotosphere);
                viewer.add(panorama);
                
                photosphereViewer = viewer;
                
            } catch (error) {
                console.error('Viewer initialization failed:', error);
                
                const img = document.createElement('img');
                img.src = window.stitchedPhotosphere;
                img.style.cssText = 'width: 100%; height: 100%; object-fit: contain;';
                viewerContainer.appendChild(img);
            }
        }

        function downloadPhotosphere() {
            if (!window.stitchedPhotosphere) {
                alert('No photosphere available for download.');
                return;
            }
            
            const link = document.createElement('a');
            link.download = `photosphere_${new Date().toISOString().slice(0, 19).replace(/:/g, '-')}.jpg`;
            link.href = window.stitchedPhotosphere;
            link.click();
        }

        function backToCapture() {
            document.getElementById('viewerInterface').style.display = 'none';
            document.getElementById('frontPage').style.display = 'block';
            
            // Reset state
            capturedImages = [];
            capturePoints = [];
            window.stitchedPhotosphere = null;
            window.optimizedPlacements = null;
            previousAlpha = null;
            
            if (threeScene) {
                dotMeshes.forEach(mesh => threeScene.remove(mesh));
                capturedImageMeshes.forEach(mesh => threeScene.remove(mesh));
                dotMeshes = [];
                capturedImageMeshes = [];
                
                if (threeRenderer) {
                    threeRenderer.dispose();
                    threeRenderer = null;
                }
                
                threeScene = null;
                threeCamera = null;
            }
            
            if (photosphereViewer) {
                photosphereViewer.dispose();
                photosphereViewer = null;
            }
        }

        function cancelCapture() {
            if (confirm('Are you sure you want to cancel? All captured images will be lost.')) {
                if (cameraStream) {
                    cameraStream.getTracks().forEach(track => track.stop());
                    cameraStream = null;
                }
                
                window.removeEventListener('deviceorientation', handleOrientation);
                backToCapture();
            }
        }

        // Handle window resize
        window.addEventListener('resize', () => {
            if (threeRenderer && threeCamera) {
                threeCamera.aspect = window.innerWidth / window.innerHeight;
                threeCamera.updateProjectionMatrix();
                threeRenderer.setSize(window.innerWidth, window.innerHeight);
            }
            
            if (arCanvas) {
                arCanvas.width = window.innerWidth;
                arCanvas.height = window.innerHeight;
            }
        });

        window.addEventListener('orientationchange', () => {
            setTimeout(() => {
                if (threeRenderer && threeCamera) {
                    threeCamera.aspect = window.innerWidth / window.innerHeight;
                    threeCamera.updateProjectionMatrix();
                    threeRenderer.setSize(window.innerWidth, window.innerHeight);
                }
                
                if (arCanvas) {
                    arCanvas.width = window.innerWidth;
                    arCanvas.height = window.innerHeight;
                }
            }, 100);
        });

        // Service worker for PWA
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', () => {
                const swCode = `
                    const CACHE_NAME = 'photosphere-v2.0.0';
                    const urlsToCache = [
                        './',
                        'https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js',
                        'https://cdnjs.cloudflare.com/ajax/libs/panolens/0.12.1/panolens.min.js'
                    ];

                    self.addEventListener('install', event => {
                        event.waitUntil(
                            caches.open(CACHE_NAME)
                                .then(cache => cache.addAll(urlsToCache))
                        );
                    });

                    self.addEventListener('fetch', event => {
                        event.respondWith(
                            caches.match(event.request)
                                .then(response => {
                                    if (response) {
                                        return response;
                                    }
                                    return fetch(event.request);
                                })
                        );
                    });
                `;
                
                const blob = new Blob([swCode], { type: 'application/javascript' });
                const swUrl = URL.createObjectURL(blob);
                
                navigator.serviceWorker.register(swUrl)
                    .then(registration => {
                        console.log('ServiceWorker registration successful');
                    })
                    .catch(error => {
                        console.log('ServiceWorker registration failed: ', error);
                    });
            });
        }

        // Initialize app
        document.addEventListener('DOMContentLoaded', () => {
            console.log('PhotoSphere Capture Pro v2.0.0 initialized');
            
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                alert('Camera API not supported on this device.');
                return;
            }
            
            if (!window.DeviceOrientationEvent) {
                console.warn('Device orientation not supported - AR features limited');
            }
            
            const canvas = document.createElement('canvas');
            const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
            if (!gl) {
                alert('WebGL not supported - 3D features will be limited.');
            }
        });

        // Prevent context menu and zoom
        document.addEventListener('contextmenu', e => e.preventDefault());
        
        let lastTouchEnd = 0;
        document.addEventListener('touchend', event => {
            const now = new Date().getTime();
            if (now - lastTouchEnd <= 300) {
                event.preventDefault();
            }
            lastTouchEnd = now;
        }, false);

    </script>
</body>
</html>
                        